# GeliÅŸtirilmiÅŸ Speech-to-Text (STT) ModÃ¼lÃ¼

Bu modÃ¼l, ses kayÄ±tlarÄ±ndan mÃ¼kemmel transkripsiyon elde etmek iÃ§in tasarlanmÄ±ÅŸ geliÅŸmiÅŸ bir ses-metin dÃ¶nÃ¼ÅŸtÃ¼rme sistemidir. Ã–zellikle TÃ¼rkÃ§e toplantÄ± kayÄ±tlarÄ±, eÄŸitim videolarÄ± ve profesyonel ses kayÄ±tlarÄ± iÃ§in optimize edilmiÅŸtir.

## ğŸŒŸ Ã–zellikler

### Ã‡oklu Model DesteÄŸi
- **Whisper Ailesi**: OpenAI Whisper (GPU/CPU), Faster-Whisper
- **Cloud API'ler**: Azure Cognitive Services, Google Cloud Speech
- **Hibrit YaklaÅŸÄ±m**: Birden fazla modeli paralel Ã§alÄ±ÅŸtÄ±rÄ±p en iyi sonucu seÃ§me

### GeliÅŸmiÅŸ Ses Ã–n Ä°ÅŸleme
- GÃ¼rÃ¼ltÃ¼ azaltma (Noise Reduction)
- Ses normalizasyonu ve temizleme
- GeliÅŸmiÅŸ Voice Activity Detection (VAD)
- Otomatik ses kalitesi analizi ve SNR tahmini

### AkÄ±llÄ± Post-Processing
- BaÄŸlam farkÄ±nda metin dÃ¼zeltme
- Teknik terim ve Ã¶zel isim optimizasyonu
- GeliÅŸmiÅŸ tekrar temizleme algoritmasÄ±
- CÃ¼mle yapÄ±sÄ± dÃ¼zeltme

### Kalite KontrolÃ¼
- Otomatik gÃ¼ven skoru hesaplama
- Transkripsiyon kalitesi deÄŸerlendirmesi
- Realtime performans metrikleri

### KonuÅŸmacÄ± Analizi
- Temel konuÅŸmacÄ± segmentasyonu
- Sessizlik bazlÄ± konuÅŸmacÄ± deÄŸiÅŸimi tespiti
- Segment dÃ¼zeyinde konuÅŸmacÄ± bilgileri

## ğŸ“¦ Kurulum

```bash
# Temel baÄŸÄ±mlÄ±lÄ±klarÄ± yÃ¼kle
pip install -r requirements.txt

# GPU desteÄŸi iÃ§in (CUDA gerekli)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# Opsiyonel: Cloud API'ler iÃ§in
pip install azure-cognitiveservices-speech google-cloud-speech
```

### Gerekli KÃ¼tÃ¼phaneler
```
faster-whisper>=1.0.0
librosa>=0.10.0
noisereduce>=3.0.0
webrtcvad>=2.0.10
pydub>=0.25.1
rapidfuzz>=3.0.0
numpy>=1.24.0
torch>=2.0.0
transformers>=4.30.0
```

## ğŸš€ HÄ±zlÄ± BaÅŸlangÄ±Ã§

### En Basit KullanÄ±m
```python
from modules.stt import transcribe_simple

# Sadece metin al
text = transcribe_simple("meeting.wav")
print(text)
```

### GeliÅŸmiÅŸ Transkripsiyon
```python
from modules.stt import transcribe_advanced

# TÃ¼m Ã¶zelliklerle
result = transcribe_advanced(
    "meeting.wav",
    language="tr",           # Dil kodu
    quality="highest",       # Kalite seviyesi
    preprocess=True,         # Ses Ã¶n iÅŸleme
    engine="auto"           # Model seÃ§imi
)

print(f"ğŸ“ Transkripsiyon: {result.text}")
print(f"ğŸ¯ GÃ¼ven Skoru: {result.confidence:.2f}")
print(f"âš¡ Model: {result.model_used}")
print(f"â±ï¸ SÃ¼re: {result.processing_time:.1f}s")
```

### ToplantÄ± KaydÄ± Analizi
```python
from modules.stt import transcribe_for_meeting

# ToplantÄ± iÃ§in optimize edilmiÅŸ analiz
result = transcribe_for_meeting("meeting.wav")

print(f"ğŸ“ Transkripsiyon: {result['transcript']}")
print(f"ğŸ‘¥ KonuÅŸmacÄ± SayÄ±sÄ±: {len(result['speakers'])}")
print(f"ğŸ“‹ Tespit Edilen GÃ¶revler: {len(result['tasks'])}")
print(f"âš–ï¸ AlÄ±nan Kararlar: {len(result['decisions'])}")

# GÃ¶revleri listele
for i, task in enumerate(result['tasks'], 1):
    print(f"  {i}. {task}")
```

### KonuÅŸmacÄ± AyrÄ±mÄ±
```python
from modules.stt import transcribe_with_speakers

result = transcribe_with_speakers("meeting.wav")

# KonuÅŸmacÄ± bazÄ±nda segment gÃ¶sterimi
for segment in result['segments']:
    speaker = segment['speaker']
    text = segment['text']
    start = segment['start']
    end = segment['end']
    
    print(f"[{start:.1f}s-{end:.1f}s] {speaker}: {text}")
```

## âš™ï¸ YapÄ±landÄ±rma SeÃ§enekleri

### Kalite Seviyeleri
- **`fastest`**: En hÄ±zlÄ± (tiny model, minimal iÅŸlem)
- **`balanced`**: Dengeli (medium model, Ã¶n iÅŸleme)
- **`highest`**: En yÃ¼ksek (large model, tÃ¼m Ã¶zellikler)
- **`hybrid`**: Ã‡oklu model karÅŸÄ±laÅŸtÄ±rma

### Model/Engine SeÃ§enekleri
- **`auto`**: Ses Ã¶zelliklerine gÃ¶re otomatik seÃ§im
- **`whisper`**: OpenAI Whisper modelleri
- **`azure`**: Azure Cognitive Services
- **`google`**: Google Cloud Speech
- **`hybrid`**: Birden fazla model paralel

### Dil KodlarÄ±
- `tr`: TÃ¼rkÃ§e (varsayÄ±lan)
- `en`: Ä°ngilizce
- `de`: Almanca
- `fr`: FransÄ±zca
- `es`: Ä°spanyolca
- Desteklenen diÄŸer diller...

## ğŸ”§ GeliÅŸmiÅŸ KullanÄ±m

### Cloud API YapÄ±landÄ±rmasÄ±

#### Azure Cognitive Services
```python
import os
os.environ["AZURE_SPEECH_KEY"] = "your-api-key"
os.environ["AZURE_SPEECH_REGION"] = "eastus"

result = transcribe_advanced("audio.wav", engine="azure")
```

#### Google Cloud Speech
```python
import os
os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = "path/to/credentials.json"

result = transcribe_advanced("audio.wav", engine="google")
```

### Ã–zel Terimler Ekleme
```python
# custom_terms.txt dosyasÄ± oluÅŸtur
with open("custom_terms.txt", "w", encoding="utf-8") as f:
    f.write("""
# Åirket Ã¶zel terimleri
KurumsalApp
VeriTabanÄ±Sistemi
ProjeAlfa
MÃ¼ÅŸteriPortalÄ±

# Teknik terimler
Kubernetes
PostgreSQL
Redis
""")
```

### Metin DÃ¼zeltme KurallarÄ±
```python
# corrections.txt dosyasÄ± oluÅŸtur
with open("corrections.txt", "w", encoding="utf-8") as f:
    f.write("""
# YaygÄ±n STT hatalarÄ±
payton => Python
cubernets => Kubernetes
veri tabanÄ± => veritabanÄ±
deil => deÄŸil
""")
```

## ğŸ“Š Performans ve Kalite

### Kalite Metrikleri
```python
result = transcribe_advanced("audio.wav", quality="highest")

if result.quality_metrics:
    metrics = result.quality_metrics
    print(f"ğŸ“ˆ Genel Kalite: {metrics['overall_score']:.2f}")
    print(f"ğŸ“ Metin Kalitesi: {metrics['text_quality']:.2f}")
    print(f"â±ï¸ Zamanlama DoÄŸruluÄŸu: {metrics['timing_accuracy']:.2f}")
    print(f"ğŸ“ TamlÄ±k: {metrics['completeness']:.2f}")
```

### Performans Optimizasyonu
```python
# Ses Ã¶zelliklerine gÃ¶re otomatik parametre ayarlama
from modules.stt import _get_audio_info, _adaptive_parameters

audio_info = _get_audio_info("audio.wav")
params = _adaptive_parameters(audio_info)

print(f"ğŸ“Š Ses Bilgileri:")
print(f"  â±ï¸ SÃ¼re: {audio_info.duration:.1f}s")
print(f"  ğŸ“ˆ SNR: {audio_info.snr_estimate:.1f}dB")
print(f"ğŸ”§ Ã–nerilen Parametreler:")
print(f"  beam_size: {params['beam_size']}")
print(f"  temperature: {params['temperature']}")
```

## ğŸ¯ En Ä°yi Uygulamalar

### Ses DosyasÄ± HazÄ±rlÄ±ÄŸÄ±
1. **Format**: WAV, 16kHz, mono tercih edilir
2. **Kalite**: SNR > 20dB iÃ§in en iyi sonuÃ§lar
3. **Uzunluk**: Segment baÅŸÄ±na 30 saniye - 10 dakika ideal
4. **GÃ¼rÃ¼ltÃ¼**: MÃ¼mkÃ¼n olduÄŸunca temiz kayÄ±t

### Model SeÃ§imi
- **KÄ±sa kayÄ±tlar** (< 5 dk): `quality="balanced"`
- **Uzun kayÄ±tlar** (> 1 saat): `engine="azure"` veya `"google"`
- **DÃ¼ÅŸÃ¼k kalite ses**: `quality="highest"` + `preprocess=True`
- **YÃ¼ksek hÄ±z gerekli**: `quality="fastest"`

### Toplu Ä°ÅŸlem
```python
import os
from pathlib import Path

# KlasÃ¶rdeki tÃ¼m ses dosyalarÄ±nÄ± iÅŸle
audio_dir = Path("audio_files")
results = []

for audio_file in audio_dir.glob("*.wav"):
    print(f"Ä°ÅŸleniyor: {audio_file.name}")
    
    try:
        result = transcribe_for_meeting(str(audio_file))
        results.append({
            "file": audio_file.name,
            "transcript": result["transcript"],
            "confidence": result["confidence"],
            "tasks": result["tasks"]
        })
    except Exception as e:
        print(f"Hata: {audio_file.name} - {e}")

# SonuÃ§larÄ± kaydet
import json
with open("batch_results.json", "w", encoding="utf-8") as f:
    json.dump(results, f, ensure_ascii=False, indent=2)
```

## ğŸ› Sorun Giderme

### YaygÄ±n Hatalar

**1. Import HatalarÄ±**
```bash
# Eksik kÃ¼tÃ¼phaneler iÃ§in
pip install librosa noisereduce webrtcvad pydub
```

**2. CUDA/GPU SorunlarÄ±**
```python
# CPU'ya zorla
result = transcribe_advanced("audio.wav", device="cpu")
```

**3. Bellek SorunlarÄ±**
```python
# Uzun kayÄ±tlar iÃ§in chunk'lara bÃ¶l
result = transcribe_advanced(
    "long_audio.wav", 
    quality="balanced",  # highest yerine
    preprocess=False     # Bellek tasarrufu iÃ§in
)
```

**4. DÃ¼ÅŸÃ¼k Kalite SonuÃ§lar**
```python
# Daha agresif Ã¶n iÅŸleme
result = transcribe_advanced(
    "noisy_audio.wav",
    quality="highest",
    preprocess=True,
    engine="hybrid"  # Birden fazla model dene
)
```

## ğŸ“ˆ GeliÅŸtirme PlanÄ±

### Gelecek Ã–zellikler
- [ ] Real-time transkripsiyon desteÄŸi
- [ ] GeliÅŸmiÅŸ speaker diarization (pyannote.audio)
- [ ] Emotion detection entegrasyonu
- [ ] WebRTC tabanlÄ± noise cancellation
- [ ] Custom model fine-tuning desteÄŸi
- [ ] REST API interface

### KatkÄ±da Bulunma
1. Repository'yi fork edin
2. Feature branch oluÅŸturun
3. DeÄŸiÅŸiklikleri commit edin
4. Pull request gÃ¶nderin

## ğŸ“„ Lisans

Bu proje MIT lisansÄ± altÄ±nda yayÄ±nlanmÄ±ÅŸtÄ±r.

## ğŸ†˜ Destek

SorunlarÄ±nÄ±z iÃ§in:
1. GitHub Issues kullanÄ±n
2. Dokumentasyonu kontrol edin
3. Test dosyasÄ±nÄ± Ã§alÄ±ÅŸtÄ±rÄ±n: `python test_enhanced_stt.py`

---

**Not**: Bu modÃ¼l sÃ¼rekli geliÅŸtirilmektedir. En son sÃ¼rÃ¼m iÃ§in repository'yi takip edin.

---

**Made by Mehmet Arda Ã‡ekiÃ§** Â© 2025