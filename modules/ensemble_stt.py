# modules/ensemble_stt.py - Multi-Model Ensemble System
"""
Ã‡oklu Model Ensemble STT Sistemi
===============================

Bu modÃ¼l %99.9 doÄŸruluk iÃ§in birden fazla STT modelini birleÅŸtirir:
- OpenAI Whisper (multiple versions)
- Azure Cognitive Services
- Google Cloud Speech-to-Text
- IBM Watson Speech to Text
- Amazon Transcribe
- AssemblyAI

Voting ve confidence-based combination ile maksimum doÄŸruluk saÄŸlar.

KullanÄ±m:
    ensemble = EnsembleSTTSystem()
    result = ensemble.transcribe_with_consensus("audio.wav")
"""

import os
import json
import asyncio
import concurrent.futures
from typing import List, Dict, Optional, Tuple, Any
from dataclasses import dataclass
from collections import Counter
import numpy as np
import time
import difflib
import re
from statistics import mode, median

try:
    import openai
    _HAS_OPENAI = True
except ImportError:
    _HAS_OPENAI = False

try:
    import azure.cognitiveservices.speech as speechsdk
    _HAS_AZURE = True
except ImportError:
    _HAS_AZURE = False

try:
    from google.cloud import speech
    _HAS_GOOGLE = True
except ImportError:
    _HAS_GOOGLE = False

try:
    import ibm_watson
    from ibm_watson import SpeechToTextV1
    _HAS_IBM = True
except ImportError:
    _HAS_IBM = False

try:
    import boto3
    _HAS_AWS = True
except ImportError:
    _HAS_AWS = False

# Local imports
try:
    from . import stt
    from . import advanced_audio
except ImportError:
    import stt
    import advanced_audio


@dataclass
class TranscriptionCandidate:
    """Bir STT modelinden gelen transkripsiyon adayÄ±"""
    text: str
    confidence: float
    model_name: str
    processing_time: float
    word_timestamps: Optional[List[Dict]] = None
    alternative_transcripts: Optional[List[str]] = None
    audio_quality_score: Optional[float] = None


@dataclass
class EnsembleResult:
    """Ensemble sonucu"""
    final_text: str
    consensus_confidence: float
    individual_results: List[TranscriptionCandidate]
    voting_details: Dict[str, Any]
    quality_metrics: Dict[str, float]
    processing_stats: Dict[str, float]


class TextSimilarityAnalyzer:
    """Metin benzerlik analizi iÃ§in geliÅŸmiÅŸ araÃ§lar"""
    
    @staticmethod
    def calculate_similarity_matrix(texts: List[str]) -> np.ndarray:
        """Metinler arasÄ± benzerlik matrisi hesapla"""
        n = len(texts)
        similarity_matrix = np.zeros((n, n))
        
        for i in range(n):
            for j in range(n):
                if i == j:
                    similarity_matrix[i, j] = 1.0
                else:
                    similarity_matrix[i, j] = TextSimilarityAnalyzer._calculate_text_similarity(
                        texts[i], texts[j]
                    )
        
        return similarity_matrix
    
    @staticmethod
    def _calculate_text_similarity(text1: str, text2: str) -> float:
        """Ä°ki metin arasÄ±nda geliÅŸmiÅŸ benzerlik hesaplama"""
        # Normalize et
        text1_clean = TextSimilarityAnalyzer._normalize_text(text1)
        text2_clean = TextSimilarityAnalyzer._normalize_text(text2)
        
        # Birden fazla metrik kullan
        
        # 1. SequenceMatcher (character-level)
        seq_similarity = difflib.SequenceMatcher(None, text1_clean, text2_clean).ratio()
        
        # 2. Word-level Jaccard similarity
        words1 = set(text1_clean.split())
        words2 = set(text2_clean.split())
        
        if len(words1) == 0 and len(words2) == 0:
            word_similarity = 1.0
        elif len(words1) == 0 or len(words2) == 0:
            word_similarity = 0.0
        else:
            intersection = len(words1 & words2)
            union = len(words1 | words2)
            word_similarity = intersection / union if union > 0 else 0.0
        
        # 3. Levenshtein distance normalized
        lev_distance = TextSimilarityAnalyzer._levenshtein_distance(text1_clean, text2_clean)
        max_len = max(len(text1_clean), len(text2_clean))
        lev_similarity = 1 - (lev_distance / max_len) if max_len > 0 else 1.0
        
        # Weighted combination
        combined_similarity = (
            0.4 * seq_similarity +
            0.4 * word_similarity +
            0.2 * lev_similarity
        )
        
        return combined_similarity
    
    @staticmethod
    def _normalize_text(text: str) -> str:
        """Metin normalizaÃ§Ã£o"""
        # KÃ¼Ã§Ã¼k harfe Ã§evir
        text = text.lower()
        
        # Noktalama iÅŸaretlerini kaldÄ±r
        text = re.sub(r'[^\w\s]', '', text)
        
        # Ã‡oklu boÅŸluklarÄ± tek boÅŸluÄŸa Ã§evir
        text = re.sub(r'\s+', ' ', text)
        
        # BaÅŸlangÄ±Ã§ ve sonundaki boÅŸluklarÄ± kaldÄ±r
        text = text.strip()
        
        return text
    
    @staticmethod
    def _levenshtein_distance(s1: str, s2: str) -> int:
        """Levenshtein distance hesaplama"""
        if len(s1) < len(s2):
            return TextSimilarityAnalyzer._levenshtein_distance(s2, s1)
        
        if len(s2) == 0:
            return len(s1)
        
        previous_row = list(range(len(s2) + 1))
        
        for i, c1 in enumerate(s1):
            current_row = [i + 1]
            
            for j, c2 in enumerate(s2):
                insertions = previous_row[j + 1] + 1
                deletions = current_row[j] + 1
                substitutions = previous_row[j] + (c1 != c2)
                
                current_row.append(min(insertions, deletions, substitutions))
            
            previous_row = current_row
        
        return previous_row[-1]


class ConsensusVoting:
    """GeliÅŸmiÅŸ consensus voting algoritmasÄ±"""
    
    @staticmethod
    def weighted_majority_voting(
        candidates: List[TranscriptionCandidate],
        similarity_threshold: float = 0.7,
        confidence_weight: float = 0.6,
        similarity_weight: float = 0.4
    ) -> Tuple[str, float, Dict]:
        """AÄŸÄ±rlÄ±klÄ± Ã§oÄŸunluk oylamasÄ±"""
        if not candidates:
            return "", 0.0, {}
        
        if len(candidates) == 1:
            return candidates[0].text, candidates[0].confidence, {"single_candidate": True}
        
        # Metin listesi
        texts = [c.text for c in candidates]
        confidences = [c.confidence for c in candidates]
        
        # Benzerlik matrisi
        similarity_matrix = TextSimilarityAnalyzer.calculate_similarity_matrix(texts)
        
        # Cluster oluÅŸtur (benzer metinleri grupla)
        clusters = ConsensusVoting._create_similarity_clusters(
            texts, similarity_matrix, similarity_threshold
        )
        
        # Her cluster iÃ§in aÄŸÄ±rlÄ±klÄ± skor hesapla
        cluster_scores = []
        
        for cluster_indices in clusters:
            cluster_candidates = [candidates[i] for i in cluster_indices]
            cluster_texts = [candidates[i].text for i in cluster_indices]
            cluster_confidences = [candidates[i].confidence for i in cluster_indices]
            
            # Cluster iÃ§inde en yÃ¼ksek confidence'a sahip metni seÃ§
            best_idx = np.argmax(cluster_confidences)
            representative_text = cluster_texts[best_idx]
            
            # Cluster skoru: confidence + similarity bonusu
            confidence_score = np.mean(cluster_confidences)
            
            # Similarity bonus: cluster bÃ¼yÃ¼klÃ¼ÄŸÃ¼ ve iÃ§sel benzerlik
            similarity_bonus = len(cluster_indices) / len(candidates)
            
            # Internal cluster similarity
            if len(cluster_indices) > 1:
                internal_similarities = []
                for i in cluster_indices:
                    for j in cluster_indices:
                        if i < j:
                            internal_similarities.append(similarity_matrix[i, j])
                avg_internal_similarity = np.mean(internal_similarities) if internal_similarities else 1.0
            else:
                avg_internal_similarity = 1.0
            
            # Final cluster score
            final_score = (
                confidence_weight * confidence_score +
                similarity_weight * similarity_bonus * avg_internal_similarity
            )
            
            cluster_scores.append({
                'text': representative_text,
                'score': final_score,
                'size': len(cluster_indices),
                'avg_confidence': confidence_score,
                'internal_similarity': avg_internal_similarity,
                'candidates': cluster_candidates
            })
        
        # En yÃ¼ksek skorlu cluster'Ä± seÃ§
        best_cluster = max(cluster_scores, key=lambda x: x['score'])
        
        voting_details = {
            'clusters': cluster_scores,
            'selected_cluster_size': best_cluster['size'],
            'consensus_strength': best_cluster['score'],
            'total_candidates': len(candidates),
            'similarity_threshold': similarity_threshold
        }
        
        return best_cluster['text'], best_cluster['score'], voting_details
    
    @staticmethod
    def _create_similarity_clusters(
        texts: List[str],
        similarity_matrix: np.ndarray,
        threshold: float
    ) -> List[List[int]]:
        """Benzerlik tabanlÄ± clustering"""
        n = len(texts)
        clusters = []
        assigned = [False] * n
        
        for i in range(n):
            if assigned[i]:
                continue
                
            # Yeni cluster baÅŸlat
            cluster = [i]
            assigned[i] = True
            
            # Benzer metinleri bu cluster'a ekle
            for j in range(i + 1, n):
                if not assigned[j] and similarity_matrix[i, j] >= threshold:
                    cluster.append(j)
                    assigned[j] = True
            
            clusters.append(cluster)
        
        return clusters


class WhisperMultiModel:
    """Multiple Whisper model handler"""
    
    def __init__(self):
        self.models = {}
        self.available_models = ["tiny", "base", "small", "medium", "large-v2", "large-v3"]
    
    async def transcribe_multiple_models(
        self,
        audio_path: str,
        language: str = "tr",
        models_to_use: Optional[List[str]] = None
    ) -> List[TranscriptionCandidate]:
        """Birden fazla Whisper modeli ile transkripsiyon"""
        
        if models_to_use is None:
            # VarsayÄ±lan: en iyi 3 model
            models_to_use = ["medium", "large-v2", "large-v3"]
        
        results = []
        
        # Her model iÃ§in paralel iÅŸlem
        with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:
            futures = []
            
            for model_name in models_to_use:
                future = executor.submit(
                    self._transcribe_single_whisper_model,
                    audio_path, model_name, language
                )
                futures.append((future, model_name))
            
            for future, model_name in futures:
                try:
                    result = future.result(timeout=300)  # 5 dakika timeout
                    if result:
                        results.append(result)
                except Exception as e:
                    print(f"Whisper {model_name} hatasÄ±: {e}")
        
        return results
    
    def _transcribe_single_whisper_model(
        self,
        audio_path: str,
        model_name: str,
        language: str
    ) -> Optional[TranscriptionCandidate]:
        """Tek Whisper modeli ile transkripsiyon"""
        try:
            start_time = time.time()
            
            # STT modÃ¼lÃ¼nÃ¼ kullan
            result = stt.transcribe_advanced(
                audio_path,
                model_name=model_name,
                language=language,
                quality="highest",
                engine="whisper"
            )
            
            processing_time = time.time() - start_time
            
            return TranscriptionCandidate(
                text=result.text if hasattr(result, 'text') else str(result),
                confidence=result.confidence if hasattr(result, 'confidence') else 0.8,
                model_name=f"whisper-{model_name}",
                processing_time=processing_time,
                word_timestamps=getattr(result, 'word_timestamps', None)
            )
            
        except Exception as e:
            print(f"Whisper {model_name} transkripsiyon hatasÄ±: {e}")
            return None


class CloudSTTServices:
    """Cloud STT servislerini yÃ¶netir"""
    
    def __init__(self):
        self.azure_client = None
        self.google_client = None
        self.ibm_client = None
        self.aws_client = None
        
    async def transcribe_all_cloud_services(
        self,
        audio_path: str,
        language: str = "tr"
    ) -> List[TranscriptionCandidate]:
        """TÃ¼m cloud servislerle transkripsiyon"""
        
        results = []
        
        # Paralel cloud service Ã§aÄŸrÄ±larÄ±
        tasks = []
        
        if _HAS_AZURE and self._check_azure_credentials():
            tasks.append(self._transcribe_azure(audio_path, language))
            
        if _HAS_GOOGLE and self._check_google_credentials():
            tasks.append(self._transcribe_google(audio_path, language))
            
        if _HAS_IBM and self._check_ibm_credentials():
            tasks.append(self._transcribe_ibm(audio_path, language))
            
        if _HAS_AWS and self._check_aws_credentials():
            tasks.append(self._transcribe_aws(audio_path, language))
        
        # EÅŸ zamanlÄ± Ã§alÄ±ÅŸtÄ±r
        if tasks:
            completed_results = await asyncio.gather(*tasks, return_exceptions=True)
            
            for result in completed_results:
                if isinstance(result, TranscriptionCandidate):
                    results.append(result)
                elif isinstance(result, Exception):
                    print(f"Cloud service hatasÄ±: {result}")
        
        return results
    
    async def _transcribe_azure(self, audio_path: str, language: str) -> Optional[TranscriptionCandidate]:
        """Azure Cognitive Services transkripsiyon"""
        try:
            if not _HAS_AZURE:
                return None
                
            start_time = time.time()
            
            # Azure Speech Service konfigÃ¼rasyonu
            speech_key = os.getenv("AZURE_SPEECH_KEY")
            service_region = os.getenv("AZURE_SPEECH_REGION", "eastus")
            
            if not speech_key:
                return None
            
            speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=service_region)
            speech_config.speech_recognition_language = self._get_azure_language_code(language)
            
            audio_config = speechsdk.audio.AudioConfig(filename=audio_path)
            speech_recognizer = speechsdk.SpeechRecognizer(
                speech_config=speech_config,
                audio_config=audio_config
            )
            
            # Continuous recognition
            result = speech_recognizer.recognize_once()
            
            processing_time = time.time() - start_time
            
            if result.reason == speechsdk.ResultReason.RecognizedSpeech:
                # Confidence Azure'dan gelmiyor, tahmini deÄŸer
                confidence = 0.85  # Azure genelde gÃ¼venilir
                
                return TranscriptionCandidate(
                    text=result.text,
                    confidence=confidence,
                    model_name="azure-cognitive-services",
                    processing_time=processing_time
                )
            else:
                print(f"Azure recognition hatasÄ±: {result.reason}")
                return None
                
        except Exception as e:
            print(f"Azure transkripsiyon hatasÄ±: {e}")
            return None
    
    async def _transcribe_google(self, audio_path: str, language: str) -> Optional[TranscriptionCandidate]:
        """Google Cloud Speech-to-Text"""
        try:
            if not _HAS_GOOGLE:
                return None
                
            start_time = time.time()
            
            client = speech.SpeechClient()
            
            # Audio dosyasÄ±nÄ± yÃ¼kle
            with open(audio_path, "rb") as audio_file:
                content = audio_file.read()
            
            audio = speech.RecognitionAudio(content=content)
            config = speech.RecognitionConfig(
                encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,
                sample_rate_hertz=16000,
                language_code=self._get_google_language_code(language),
                enable_automatic_punctuation=True,
                enable_word_confidence=True,
                model="latest_long"  # En iyi model
            )
            
            response = client.recognize(config=config, audio=audio)
            
            processing_time = time.time() - start_time
            
            if response.results:
                # En iyi alternatifi seÃ§
                best_result = response.results[0]
                best_alternative = best_result.alternatives[0]
                
                # Word-level confidence'larÄ±n ortalamasÄ±
                word_confidences = [word.confidence for word in best_alternative.words]
                avg_confidence = np.mean(word_confidences) if word_confidences else 0.8
                
                return TranscriptionCandidate(
                    text=best_alternative.transcript,
                    confidence=avg_confidence,
                    model_name="google-cloud-stt",
                    processing_time=processing_time
                )
            else:
                return None
                
        except Exception as e:
            print(f"Google Cloud STT hatasÄ±: {e}")
            return None
    
    async def _transcribe_ibm(self, audio_path: str, language: str) -> Optional[TranscriptionCandidate]:
        """IBM Watson Speech to Text"""
        try:
            if not _HAS_IBM:
                return None
                
            start_time = time.time()
            
            api_key = os.getenv("IBM_WATSON_API_KEY")
            url = os.getenv("IBM_WATSON_URL")
            
            if not api_key or not url:
                return None
            
            authenticator = ibm_watson.IAMAuthenticator(api_key)
            speech_to_text = SpeechToTextV1(authenticator=authenticator)
            speech_to_text.set_service_url(url)
            
            with open(audio_path, 'rb') as audio_file:
                speech_recognition_results = speech_to_text.recognize(
                    audio=audio_file,
                    content_type='audio/wav',
                    model=self._get_ibm_model_name(language),
                    word_confidence=True,
                    timestamps=True
                ).get_result()
            
            processing_time = time.time() - start_time
            
            if speech_recognition_results['results']:
                best_result = speech_recognition_results['results'][0]
                best_alternative = best_result['alternatives'][0]
                
                # Confidence IBM'den geliyor
                confidence = best_alternative.get('confidence', 0.8)
                
                return TranscriptionCandidate(
                    text=best_alternative['transcript'],
                    confidence=confidence,
                    model_name="ibm-watson-stt",
                    processing_time=processing_time
                )
            else:
                return None
                
        except Exception as e:
            print(f"IBM Watson STT hatasÄ±: {e}")
            return None
    
    async def _transcribe_aws(self, audio_path: str, language: str) -> Optional[TranscriptionCandidate]:
        """Amazon Transcribe"""
        try:
            if not _HAS_AWS:
                return None
                
            start_time = time.time()
            
            # AWS Transcribe real-time veya batch iÅŸlemi gerektirir
            # Bu Ã¶rnekte basitleÅŸtirilmiÅŸ implementasyon
            
            # NOT: AWS Transcribe gerÃ§ek implementasyonu daha karmaÅŸÄ±k
            # Job submission ve polling gerektirir
            
            processing_time = time.time() - start_time
            
            # Placeholder - gerÃ§ek AWS implementasyonu yapÄ±lacak
            return None
            
        except Exception as e:
            print(f"AWS Transcribe hatasÄ±: {e}")
            return None
    
    def _check_azure_credentials(self) -> bool:
        """Azure credentials kontrol"""
        return bool(os.getenv("AZURE_SPEECH_KEY"))
    
    def _check_google_credentials(self) -> bool:
        """Google credentials kontrol"""
        return bool(os.getenv("GOOGLE_APPLICATION_CREDENTIALS"))
    
    def _check_ibm_credentials(self) -> bool:
        """IBM credentials kontrol"""
        return bool(os.getenv("IBM_WATSON_API_KEY"))
    
    def _check_aws_credentials(self) -> bool:
        """AWS credentials kontrol"""
        return bool(os.getenv("AWS_ACCESS_KEY_ID"))
    
    def _get_azure_language_code(self, language: str) -> str:
        """Azure dil kodu mapping"""
        mapping = {
            "tr": "tr-TR",
            "en": "en-US", 
            "de": "de-DE",
            "fr": "fr-FR",
            "es": "es-ES",
            "it": "it-IT"
        }
        return mapping.get(language, "tr-TR")
    
    def _get_google_language_code(self, language: str) -> str:
        """Google dil kodu mapping"""
        mapping = {
            "tr": "tr-TR",
            "en": "en-US",
            "de": "de-DE", 
            "fr": "fr-FR",
            "es": "es-ES",
            "it": "it-IT"
        }
        return mapping.get(language, "tr-TR")
    
    def _get_ibm_model_name(self, language: str) -> str:
        """IBM model adÄ± mapping"""
        mapping = {
            "tr": "tr-TR_BroadbandModel",
            "en": "en-US_BroadbandModel",
            "de": "de-DE_BroadbandModel",
            "fr": "fr-FR_BroadbandModel", 
            "es": "es-ES_BroadbandModel",
            "it": "it-IT_BroadbandModel"
        }
        return mapping.get(language, "tr-TR_BroadbandModel")


class EnsembleSTTSystem:
    """Ana ensemble STT sistemi"""
    
    def __init__(self, config: Optional[Dict] = None):
        self.config = config or {}
        self.whisper_handler = WhisperMultiModel()
        self.cloud_services = CloudSTTServices()
        self.audio_processor = advanced_audio.UltraAudioProcessor()
        
    async def transcribe_with_consensus(
        self,
        audio_path: str,
        language: str = "tr",
        quality_mode: str = "maximum",  # "fast", "balanced", "high", "maximum" 
        enable_cloud_services: bool = True,
        custom_models: Optional[List[str]] = None
    ) -> EnsembleResult:
        """Consensus tabanlÄ± ensemble transkripsiyon"""
        
        start_time = time.time()
        
        # 1. Audio preprocessing - ultra quality
        print("ðŸŽµ Audio preprocessing...")
        enhanced_audio, audio_log = self.audio_processor.enhance_for_maximum_accuracy(audio_path)
        
        # GeÃ§ici enhanced audio dosyasÄ± kaydet
        import tempfile
        import soundfile as sf
        
        with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as tmp_file:
            enhanced_audio_path = tmp_file.name
            sf.write(enhanced_audio_path, enhanced_audio, 16000)
        
        try:
            # 2. Multiple model transcription
            all_candidates = []
            
            # Whisper models
            print("ðŸ¤– Whisper models transkripsiyon...")
            whisper_models = self._select_whisper_models(quality_mode, custom_models)
            whisper_results = await self.whisper_handler.transcribe_multiple_models(
                enhanced_audio_path, language, whisper_models
            )
            all_candidates.extend(whisper_results)
            
            # Cloud services (opsiyonel)
            if enable_cloud_services:
                print("â˜ï¸ Cloud services transkripsiyon...")
                cloud_results = await self.cloud_services.transcribe_all_cloud_services(
                    enhanced_audio_path, language
                )
                all_candidates.extend(cloud_results)
            
            # 3. Consensus voting
            print("ðŸ—³ï¸ Consensus voting...")
            
            if not all_candidates:
                raise Exception("HiÃ§bir STT modeli sonuÃ§ Ã¼retmedi")
            
            # Similarity threshold quality_mode'a gÃ¶re ayarla
            similarity_threshold = self._get_similarity_threshold(quality_mode)
            
            final_text, consensus_confidence, voting_details = ConsensusVoting.weighted_majority_voting(
                all_candidates,
                similarity_threshold=similarity_threshold,
                confidence_weight=0.6,
                similarity_weight=0.4
            )
            
            # 4. Quality metrics
            quality_metrics = self._calculate_quality_metrics(
                all_candidates, voting_details, audio_log
            )
            
            # 5. Processing stats
            total_time = time.time() - start_time
            processing_stats = {
                'total_processing_time': total_time,
                'num_models_used': len(all_candidates),
                'audio_preprocessing_time': sum(audio_log.get('step_times', {}).values()),
                'consensus_strength': consensus_confidence
            }
            
            return EnsembleResult(
                final_text=final_text,
                consensus_confidence=consensus_confidence,
                individual_results=all_candidates,
                voting_details=voting_details,
                quality_metrics=quality_metrics,
                processing_stats=processing_stats
            )
            
        finally:
            # GeÃ§ici dosyayÄ± temizle
            try:
                os.unlink(enhanced_audio_path)
            except:
                pass
    
    def _select_whisper_models(
        self,
        quality_mode: str,
        custom_models: Optional[List[str]]
    ) -> List[str]:
        """Quality mode'a gÃ¶re Whisper modelleri seÃ§"""
        
        if custom_models:
            return custom_models
        
        model_sets = {
            "fast": ["small"],
            "balanced": ["medium", "large-v2"],
            "high": ["medium", "large-v2", "large-v3"],
            "maximum": ["small", "medium", "large-v2", "large-v3"]  # Ã‡eÅŸitlilik iÃ§in small dahil
        }
        
        return model_sets.get(quality_mode, model_sets["high"])
    
    def _get_similarity_threshold(self, quality_mode: str) -> float:
        """Quality mode'a gÃ¶re benzerlik eÅŸiÄŸi"""
        thresholds = {
            "fast": 0.6,
            "balanced": 0.65, 
            "high": 0.7,
            "maximum": 0.75
        }
        return thresholds.get(quality_mode, 0.7)
    
    def _calculate_quality_metrics(
        self,
        candidates: List[TranscriptionCandidate],
        voting_details: Dict,
        audio_log: Dict
    ) -> Dict[str, float]:
        """Kalite metriklerini hesapla"""
        
        metrics = {}
        
        # Model agreement (consensus strength)
        metrics['model_agreement'] = voting_details.get('consensus_strength', 0.0)
        
        # Average confidence across models
        confidences = [c.confidence for c in candidates]
        metrics['average_confidence'] = np.mean(confidences) if confidences else 0.0
        metrics['confidence_std'] = np.std(confidences) if len(confidences) > 1 else 0.0
        
        # Audio quality impact
        audio_quality = audio_log.get('final_quality', {}).get('quality_score', 50.0)
        metrics['audio_quality_score'] = audio_quality
        
        # Processing diversity (farklÄ± modellerin katÄ±lÄ±mÄ±)
        unique_models = len(set(c.model_name for c in candidates))
        metrics['model_diversity'] = unique_models / max(len(candidates), 1)
        
        # Text length consistency 
        text_lengths = [len(c.text) for c in candidates]
        if len(text_lengths) > 1:
            metrics['length_consistency'] = 1.0 - (np.std(text_lengths) / np.mean(text_lengths))
        else:
            metrics['length_consistency'] = 1.0
        
        # Overall quality score
        metrics['overall_quality'] = (
            0.3 * metrics['model_agreement'] +
            0.25 * metrics['average_confidence'] + 
            0.2 * (audio_quality / 100.0) +
            0.15 * metrics['model_diversity'] +
            0.1 * metrics['length_consistency']
        ) * 100
        
        return metrics


# Kolay kullanÄ±m fonksiyonlarÄ±
async def transcribe_with_maximum_accuracy(
    audio_path: str,
    language: str = "tr",
    enable_cloud: bool = False
) -> str:
    """Tek fonksiyon ile maksimum doÄŸruluk transkripsiyon"""
    
    ensemble = EnsembleSTTSystem()
    result = await ensemble.transcribe_with_consensus(
        audio_path=audio_path,
        language=language,
        quality_mode="maximum",
        enable_cloud_services=enable_cloud
    )
    
    return result.final_text


def transcribe_sync_maximum_accuracy(
    audio_path: str, 
    language: str = "tr",
    enable_cloud: bool = False
) -> EnsembleResult:
    """Senkron wrapper"""
    import asyncio
    
    ensemble = EnsembleSTTSystem()
    
    return asyncio.run(ensemble.transcribe_with_consensus(
        audio_path=audio_path,
        language=language, 
        quality_mode="maximum",
        enable_cloud_services=enable_cloud
    ))


if __name__ == "__main__":
    # Test kodu
    print("ðŸŽ¯ Multi-Model Ensemble STT System")
    print("=" * 50)
    
    available_services = []
    if _HAS_OPENAI: available_services.append("OpenAI Whisper")
    if _HAS_AZURE: available_services.append("Azure Cognitive Services")
    if _HAS_GOOGLE: available_services.append("Google Cloud Speech")
    if _HAS_IBM: available_services.append("IBM Watson")
    if _HAS_AWS: available_services.append("Amazon Transcribe")
    
    print(f"âœ… Mevcut servisler: {', '.join(available_services)}")
    print("ðŸš€ Maximum accuracy ensemble system ready!")
    
    # Test similarity analyzer
    test_texts = [
        "Bu bir test cÃ¼mlesidir",
        "Bu bir deneme cÃ¼mlesidir", 
        "Bu farklÄ± bir metindir"
    ]
    
    similarity_matrix = TextSimilarityAnalyzer.calculate_similarity_matrix(test_texts)
    print(f"\nðŸ“Š Similarity matrix Ã¶rneÄŸi:")
    print(similarity_matrix)